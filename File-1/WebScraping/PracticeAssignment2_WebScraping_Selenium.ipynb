{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31dd1500",
   "metadata": {},
   "source": [
    "# Assignment 2:WebScraping_Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d914e74a",
   "metadata": {},
   "source": [
    "Instructions\n",
    "1. All the questions must be done in a single Jupyternotebook.\n",
    "2. There should be proper comments in code.\n",
    "\n",
    "\n",
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location.\n",
    "You have to scrape the job-title, job-location, company_name, experience_required. You have to\n",
    "scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually.\n",
    "\n",
    "\n",
    "Q2: Write a python program to scrape data for ““Data Scientist” Job position in “Bangalore” location.\n",
    "You have to scrape the job-title, job-location, company_name, experience_required. You have to\n",
    "scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually.\n",
    "\n",
    "\n",
    "Q3: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search fieldwhere “search for products, brands and more” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100sunglasses. Note: That all of the above steps have to be done\n",
    "by coding only and not manually.\n",
    "Note: That all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c94e3825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in ./anaconda3/lib/python3.11/site-packages (4.18.1)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in ./anaconda3/lib/python3.11/site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in ./anaconda3/lib/python3.11/site-packages (from selenium) (0.24.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in ./anaconda3/lib/python3.11/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in ./anaconda3/lib/python3.11/site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in ./anaconda3/lib/python3.11/site-packages (from selenium) (4.10.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in ./anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in ./anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in ./anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in ./anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in ./anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in ./anaconda3/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in ./anaconda3/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in ./anaconda3/lib/python3.11/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium  #Installing the selenium library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c63c1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the webdriver for the web browser\n",
    "#Import all the required libraries\n",
    "\n",
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6f8847",
   "metadata": {},
   "source": [
    "Solution1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d819e123",
   "metadata": {},
   "source": [
    "1.First get the webpage https://www.shine.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8d0d3fe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()              # for just opening the google chrome webdriver\n",
    "driver.get(\"https://www.shine.com/\")   # for opening the website(https://www.shine.com/) in google chrome webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e113e4eb",
   "metadata": {},
   "source": [
    "2.Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "cbf0a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find element for job search bar and Enter the Data Analyst\n",
    "Designation_= driver.find_element(By.CLASS_NAME,'form-control  ') \n",
    "Designation_.send_keys(\"Data Analyst\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "28ff89ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find element for job location bar and Enter Bangalore\n",
    "Location_= driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input \")\n",
    "Location_.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e283f88",
   "metadata": {},
   "source": [
    "3. click the searchbutton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e986559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find element for Search  button and click the search button\n",
    "Search_button=driver.find_element(By.XPATH,'//button[@type=\"submit\"]')\n",
    "Search_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dd4733",
   "metadata": {},
   "source": [
    "4. scrape the data for the first 10 jobs results you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "23fb4054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Clinical Data Analyst', 'Data Analyst', 'Hiring For Data Analyst', 'Lead Data Analyst', 'Data Analyst', 'Technical Data Architect', 'Data Science Architect', 'Data Engineer', 'Clinical Data Associate', 'Part-Time Data Entry Operator work']\n",
      "['Bangalore\\n+6', 'Bangalore\\n+9', 'Bangalore\\n+12', 'Bangalore', 'Bangalore\\n+3', 'Bangalore', 'Bangalore\\n+4', 'Bangalore', 'Bangalore\\n+6', 'Bangalore\\n+9']\n",
      "['techno endura', 'sahast sales corporation', 'radhika enterprises', 'ara resources private limited', 'diraa hr services hiring for mncs', 'uprighthc solutions private limited', 'symphoni hr pvt. ltd.', 'spm hr solutions', 'techno endura', 'aspect solution']\n",
      "['0 to 1 Yr', '12 to 22 Yrs', '0 to 4 Yrs', '4 to 9 Yrs', '0 to 1 Yr', '10 to 20 Yrs', '8 to 10 Yrs', '4 to 6 Yrs', '0 to 1 Yr', '0 to 1 Yr']\n"
     ]
    }
   ],
   "source": [
    "jobtitle=[]\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "#To scrap all the job-titles from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//a[starts-with(@href,\"/jobs/\")]'):\n",
    "    jobtitle.append(i.text)\n",
    "    job_title=jobtitle[2:22]\n",
    "print(job_title[:10])\n",
    "#To scrap all the job-locations from the given page\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]'):\n",
    "    job_location.append(i.text)\n",
    "print(job_location[:10])\n",
    "#To scrap all the company-names from the given page\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]/span'):\n",
    "    company_name.append(i.text)\n",
    "print(company_name[:10])\n",
    "#To scrap all the experience-requirements from the given page\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]'):\n",
    "    experience_required.append(i.text)\n",
    "print(experience_required[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "d5a15e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "#checking the length of each of the list\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184393d5",
   "metadata": {},
   "source": [
    "5. Finally create a dataframe of the scraped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "5bbfe164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 4)\n",
      "                            Job Title    Job Location  \\\n",
      "0               Clinical Data Analyst   Bangalore\\n+6   \n",
      "1                        Data Analyst   Bangalore\\n+9   \n",
      "2             Hiring For Data Analyst  Bangalore\\n+12   \n",
      "3                   Lead Data Analyst       Bangalore   \n",
      "4                        Data Analyst   Bangalore\\n+3   \n",
      "5            Technical Data Architect       Bangalore   \n",
      "6              Data Science Architect   Bangalore\\n+4   \n",
      "7                       Data Engineer       Bangalore   \n",
      "8             Clinical Data Associate   Bangalore\\n+6   \n",
      "9  Part-Time Data Entry Operator work   Bangalore\\n+9   \n",
      "\n",
      "                          Company Name Experience Required  \n",
      "0                        techno endura           0 to 1 Yr  \n",
      "1             sahast sales corporation        12 to 22 Yrs  \n",
      "2                  radhika enterprises          0 to 4 Yrs  \n",
      "3        ara resources private limited          4 to 9 Yrs  \n",
      "4    diraa hr services hiring for mncs           0 to 1 Yr  \n",
      "5  uprighthc solutions private limited        10 to 20 Yrs  \n",
      "6                symphoni hr pvt. ltd.         8 to 10 Yrs  \n",
      "7                     spm hr solutions          4 to 6 Yrs  \n",
      "8                        techno endura           0 to 1 Yr  \n",
      "9                      aspect solution           0 to 1 Yr  \n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe of the scraped data\n",
    "jobs=pd.DataFrame({'Job Title':job_title,'Job Location':job_location,'Company Name':company_name,'Experience Required':experience_required})\n",
    "print(jobs.shape)\n",
    "print(jobs.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4df46c",
   "metadata": {},
   "source": [
    "Solution 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbcec21",
   "metadata": {},
   "source": [
    "1. First get the webpage https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5259dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()              # for just opening the google chrome webdriver\n",
    "driver.get(\"https://www.naukri.com/\")   # for opening the website(https://www.naukri.com/) in google chrome webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77e013e",
   "metadata": {},
   "source": [
    "2. Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e3b14454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find element for job search bar and Enter the Data Analyst\n",
    "Designation_= driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[1]/div/div/div/div[1]/div/input\")\n",
    "Designation_.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "33327c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find element for job location bar and Enter Bangalore\n",
    "Location_= driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "Location_.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a43d82",
   "metadata": {},
   "source": [
    "3. click the searchbutton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6e6c789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find element for Search  button and click the search button\n",
    "Search_button=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "Search_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9687e7",
   "metadata": {},
   "source": [
    "4. scrape the data for the first 10 jobs results you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eaa33612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "#To scrap all the job-titles from the given page\n",
    "for i in driver.find_elements(By.XPATH, '//div[@class=\"cust-job-tuple layout-wrapper lay-2 sjw__tuple \"]/div/a'):\n",
    "    job_title.append(i.text)\n",
    "print(job_title[:10])\n",
    "\n",
    "#To scrap all the job-locations from the given page\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"locWdth\"]'):\n",
    "    job_location.append(i.text)\n",
    "print(job_location[:10])\n",
    "\n",
    "#To scrap all the company-names from the given page\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\" row2\"]/span/a[1]'):\n",
    "    company_name.append(i.text)\n",
    "print(company_name[:10])\n",
    "\n",
    "#To scrap all the experience-requirements from the given page\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"expwdth\"]'):\n",
    "    experience_required.append(i.text)\n",
    "print(experience_required[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5e947613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "#checking the length of each of the list\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7cb920",
   "metadata": {},
   "source": [
    "5. Finally create a dataframe of the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f737b89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            job_title  \\\n",
      "0                                        Data Analyst   \n",
      "1                                        Data Analyst   \n",
      "2                                        Data Analyst   \n",
      "3                                        Data Analyst   \n",
      "4                                        Data Analyst   \n",
      "5                      Job opportunity _ Data Analyst   \n",
      "6                      Data Sourcing & Triage Analyst   \n",
      "7                                 Online Data Analyst   \n",
      "8                                        Data Analyst   \n",
      "9                           Data Services Analyst III   \n",
      "10  AWS Data Engineer/Data Analyst - Need Immediat...   \n",
      "11                                       Data Analyst   \n",
      "12                                       Data Analyst   \n",
      "13                                       Data Analyst   \n",
      "14                                       Data Analyst   \n",
      "15                              Platform Data Analyst   \n",
      "16                                       Data Analyst   \n",
      "17                                 ETL - Data Analyst   \n",
      "18                          Data Analyst (automotive)   \n",
      "19                                  FHIR Data Analyst   \n",
      "\n",
      "                                         job_location  \\\n",
      "0                                           Bengaluru   \n",
      "1                                   Mumbai, Bengaluru   \n",
      "2                                              Remote   \n",
      "3   Hybrid - Bangalore Rural, Karnataka, Hyderabad...   \n",
      "4                       Bengaluru(4th Phase JP Nagar)   \n",
      "5   Bangalore Rural, Karnataka, Hyderabad, Telanga...   \n",
      "6                                           Bengaluru   \n",
      "7   Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...   \n",
      "8                   Hyderabad, Bengaluru, Delhi / NCR   \n",
      "9                                           Bengaluru   \n",
      "10   Bangalore Rural, Karnataka, Hyderabad, Telangana   \n",
      "11                               Hyderabad, Bengaluru   \n",
      "12                  Hyderabad, Bengaluru, Delhi / NCR   \n",
      "13                                          Bengaluru   \n",
      "14                                          Bengaluru   \n",
      "15                                          Bengaluru   \n",
      "16              Hybrid - Bengaluru(Bannerghatta Road)   \n",
      "17                                          Bengaluru   \n",
      "18                        Bangalore/Bengaluru(Domlur)   \n",
      "19                                          Bengaluru   \n",
      "\n",
      "                            company_name experience_required  \n",
      "0                                 Target             2-4 Yrs  \n",
      "1             FedEx TSCS (India) Pvt Ltd             1-4 Yrs  \n",
      "2                           Puresoftware            5-10 Yrs  \n",
      "3              Tsit Digital Technologies            5-10 Yrs  \n",
      "4                   Objectwin Technology             1-5 Yrs  \n",
      "5                       Talent Sketchers            6-10 Yrs  \n",
      "6                                  Janes             0-3 Yrs  \n",
      "7                    TELUS International             1-4 Yrs  \n",
      "8                   Incanus Technologies             0-5 Yrs  \n",
      "9                              Zoom Info             4-8 Yrs  \n",
      "10                              Deloitte             5-8 Yrs  \n",
      "11                     Team Lease Dgital            6-10 Yrs  \n",
      "12       Tata Consultancy Services (TCS)             4-9 Yrs  \n",
      "13                               Softtek             4-6 Yrs  \n",
      "14                     NetSkope Software             3-5 Yrs  \n",
      "15                              Saltmine             2-4 Yrs  \n",
      "16                             LKQ India             2-5 Yrs  \n",
      "17                                 2coms            5-10 Yrs  \n",
      "18  Fenyes Engineered Technology Pvt Ltd             5-6 Yrs  \n",
      "19                               Infosys             3-6 Yrs  \n",
      "(20, 4)\n",
      "                        job_title  \\\n",
      "0                    Data Analyst   \n",
      "1                    Data Analyst   \n",
      "2                    Data Analyst   \n",
      "3                    Data Analyst   \n",
      "4                    Data Analyst   \n",
      "5  Job opportunity _ Data Analyst   \n",
      "6  Data Sourcing & Triage Analyst   \n",
      "7             Online Data Analyst   \n",
      "8                    Data Analyst   \n",
      "9       Data Services Analyst III   \n",
      "\n",
      "                                        job_location  \\\n",
      "0                                          Bengaluru   \n",
      "1                                  Mumbai, Bengaluru   \n",
      "2                                             Remote   \n",
      "3  Hybrid - Bangalore Rural, Karnataka, Hyderabad...   \n",
      "4                      Bengaluru(4th Phase JP Nagar)   \n",
      "5  Bangalore Rural, Karnataka, Hyderabad, Telanga...   \n",
      "6                                          Bengaluru   \n",
      "7  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...   \n",
      "8                  Hyderabad, Bengaluru, Delhi / NCR   \n",
      "9                                          Bengaluru   \n",
      "\n",
      "                 company_name experience_required  \n",
      "0                      Target             2-4 Yrs  \n",
      "1  FedEx TSCS (India) Pvt Ltd             1-4 Yrs  \n",
      "2                Puresoftware            5-10 Yrs  \n",
      "3   Tsit Digital Technologies            5-10 Yrs  \n",
      "4        Objectwin Technology             1-5 Yrs  \n",
      "5            Talent Sketchers            6-10 Yrs  \n",
      "6                       Janes             0-3 Yrs  \n",
      "7         TELUS International             1-4 Yrs  \n",
      "8        Incanus Technologies             0-5 Yrs  \n",
      "9                   Zoom Info             4-8 Yrs  \n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe of the scraped data\n",
    "df=pd.DataFrame({'job_title':jobtitle,'job_location':job_location,'company_name':company_name,'experience_required':experience_required}) \n",
    "print(df.shape)\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29189203",
   "metadata": {},
   "source": [
    "Solution 3:-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1678ab1b",
   "metadata": {},
   "source": [
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b67c7d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()              # for just opening the google chrome webdriver\n",
    "driver.get(\"https://www.flipkart.com/\")   # for opening the website(https://www.shine.com/) in google chrome webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e05c69a",
   "metadata": {},
   "source": [
    "2. Enter “sunglasses” in the search fieldwhere “search for products, brands and more” is written and\n",
    "click the search icon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a285be2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To import the Keys library for enter key\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "#To find element for Sunglasses in search bar and write the Sunglasses and pressing the Enter key.\n",
    "Sunglasses= driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div/div/div[1]/div[1]/header/div[1]/div[2]/form/div/div/input\")\n",
    "Sunglasses.send_keys(\"Sunglasses\")\n",
    "Sunglasses.send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b661b5bc",
   "metadata": {},
   "source": [
    "3. Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "Brand\n",
    "ProductDescription\n",
    "Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "929f9848",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]\n",
    "Product_Description=[]\n",
    "Price=[]\n",
    "# giving the start and end range of the pages for scraping the sunglasses\n",
    "start=0  # start page\n",
    "end=3    # end page\n",
    "for page in range(start,end):\n",
    "    brand_names=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]') # To scrape all the brand names of sunglasses from start page to end page after clicking on the next button\n",
    "    ProductDescriptions=driver.find_elements(By.XPATH,'//a[contains(@class,\"IRpwTa\")]')# To scrape all the product description of the sunglasses from start page to end page after clicking on the next button\n",
    "    price=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')# To scrape all the prices of sunglasses from start page to end page after clicking on the next button\n",
    "    for i in brand_names:\n",
    "        Brand.append(i.text)  \n",
    "    for j in ProductDescriptions:\n",
    "        Product_Description.append(j.text)\n",
    "    for k in price:\n",
    "        Price.append(k.text)\n",
    "    # to find the element of the next button and then click on the next button\n",
    "    next_button=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]/span')\n",
    "    next_button.click()\n",
    "    # for giving some time delay jumping from one page to another\n",
    "    time.sleep(2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "96f2bfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VINCENT CHASE', 'ROYAL SON', 'VINCENT CHASE', 'PIRASO', 'Elligator', 'PIRASO', 'VINCENT CHASE', 'VINCENT CHASE', 'VINCENT CHASE', 'Fastrack', 'ROZZETTA CRAFT', 'Lenskart STUDIO', 'Rich Club', 'VINCENT CHASE', 'Elligator', 'PIRASO', 'VINCENT CHASE', 'VINCENT CHASE', 'SRPM', 'PIRASO', 'VINCENT CHASE', 'Hooper', 'VINCENT CHASE', 'ROADWAY', 'Elligator', 'VINCENT CHASE', 'VINCENT CHASE', 'Eyewearlabs', 'hipe', 'Fastrack', 'Eyewearlabs', 'VINCENT CHASE', 'PIRASO', 'PIRASO', 'VINCENT CHASE', 'PIRASO', 'ROYAL SON', 'Eyewearlabs', 'PIRASO', 'RBGIIT', 'Eyewearlabs', 'Hooper', 'HRX by Hrithik Roshan', 'Fastrack', 'PIRASO', 'ROZZETTA CRAFT', 'ROYAL SON', 'ROYAL SON', 'VINCENT CHASE', 'CASSOWARY', 'Lenskart STUDIO', 'VINCENT CHASE', 'PIRASO', 'AISLIN', 'Roadster', 'VINCENT CHASE', 'ROYAL SON', 'ROYAL SON', 'PROVOGUE', 'BABYMOON', 'ROYAL SON', 'VINCENT CHASE', 'VINCENT CHASE', 'ROADWAY', 'Fastrack', 'PC STAR', 'Hooper', 'ROYAL SON', 'Rich Club', 'PIRASO', 'ROYAL SON', 'ROYAL SON', 'IDEE', 'VINCENT CHASE', 'ROADWAY', 'Fastrack', 'VINCENT CHASE', 'ROYAL SON', 'Eyenaks', 'PIRASO', 'ROYAL SON', 'Eyewearlabs', 'VINCENT CHASE', 'Elligator', 'PIRASO', 'VINCENT CHASE', 'Lenskart STUDIO', 'ROYAL SON', 'Elligator', 'NuVew', 'ROYAL SON', 'VINCENT CHASE', 'AISLIN', 'VINCENT CHASE', 'Fastrack', 'AISLIN', 'Nicole Miller', 'AISLIN', 'PIRASO', 'PC STAR', 'NuVew', 'NuVew', 'VINCENT CHASE', 'IRUS', 'PETER JONES', 'ROZZETTA CRAFT', 'AISLIN', 'ROYAL SON', 'Singco India', 'Fastrack', 'ROYAL SON', 'ROYAL SON', 'PC STAR', 'Fastrack', 'VINCENT CHASE', 'VINCENT CHASE', 'Hooper', 'AISLIN', 'PC STAR', 'VINCENT CHASE']\n",
      "['by Lenskart Polarized, UV Protection Sports Sunglasses ...', 'UV Protection Rectangular, Retro Square Sunglasses (58)', 'by Lenskart Polarized, UV Protection Wayfarer Sunglasse...', 'UV Protection Butterfly Sunglasses (60)', 'UV Protection Round Sunglasses (53)', 'UV Protection Aviator Sunglasses (54)', 'by Lenskart UV Protection Retro Square Sunglasses (50)', 'by Lenskart Polarized, UV Protection Rectangular Sungla...', 'by Lenskart Polarized, UV Protection Wayfarer Sunglasse...', 'UV Protection Aviator Sunglasses (58)', 'UV Protection Retro Square Sunglasses (Free Size)', 'UV Protection Rectangular Sunglasses (52)', 'UV Protection Retro Square Sunglasses (54)', 'by Lenskart Polarized, UV Protection Round Sunglasses (...', 'UV Protection Wayfarer Sunglasses (52)', 'UV Protection Aviator Sunglasses (Free Size)', 'by Lenskart Polarized, UV Protection Aviator Sunglasses...', 'by Lenskart Polarized, UV Protection Wayfarer Sunglasse...', 'UV Protection, Gradient Aviator Sunglasses (56)', 'UV Protection Butterfly Sunglasses (60)', 'by Lenskart UV Protection Cat-eye Sunglasses (61)', 'UV Protection Rectangular Sunglasses (46)', 'by Lenskart UV Protection Clubmaster Sunglasses (55)', 'UV Protection Retro Square, Wayfarer, Sports Sunglasses...', 'UV Protection Cat-eye, Retro Square, Oval, Round Sungla...', 'by Lenskart Polarized, UV Protection Wayfarer Sunglasse...', 'by Lenskart Polarized, UV Protection Wayfarer Sunglasse...', 'Polarized, UV Protection Retro Square Sunglasses (54)', 'UV Protection, Riding Glasses, Gradient Wrap-around, Sp...', 'UV Protection Wayfarer Sunglasses (Free Size)', 'Polarized, UV Protection Rectangular Sunglasses (65)', 'by Lenskart Polarized, UV Protection Spectacle Sunglas...', 'UV Protection Retro Square Sunglasses (54)', 'UV Protection Aviator Sunglasses (56)', 'by Lenskart Polarized, UV Protection Round Sunglasses (...', 'UV Protection Cat-eye Sunglasses (55)', 'UV Protection Round, Over-sized Sunglasses (Free Size)', 'Polarized, UV Protection Round Sunglasses (48)', 'UV Protection Wayfarer Sunglasses (56)', 'Night Vision, UV Protection, Polarized Wrap-around Sung...', 'Polarized, UV Protection Retro Square Sunglasses (54)', 'UV Protection Wayfarer Sunglasses (45)', 'Polarized Aviator Sunglasses (59)', 'Gradient, UV Protection Wayfarer Sunglasses (Free Size)', 'UV Protection Butterfly Sunglasses (60)', 'UV Protection Retro Square Sunglasses (Free Size)', 'Polarized, UV Protection Retro Square Sunglasses (55)', 'UV Protection Round, Over-sized Sunglasses (Free Size)', 'by Lenskart Polarized, UV Protection Cat-eye Sunglasses...', 'Riding Glasses, Night Vision, UV Protection Wrap-around...', 'Polarized, UV Protection Rectangular Sunglasses (55)', 'by Lenskart Polarized, UV Protection Wayfarer Sunglasse...', 'UV Protection Aviator Sunglasses (55)', 'Polarized, UV Protection Wayfarer Sunglasses (53)', 'UV Protection Oval Sunglasses (58)', 'by Lenskart Polarized, UV Protection Aviator Sunglasses...', 'Polarized Rectangular Sunglasses (60)', 'Mirrored Aviator Sunglasses (55)', 'UV Protection Round Sunglasses (Free Size)', 'UV Protection Round Sunglasses (Free Size)', 'UV Protection, Gradient Butterfly Sunglasses (62)', 'by Lenskart UV Protection Wayfarer Sunglasses (59)', 'by Lenskart Polarized, UV Protection Wayfarer Sunglasse...', 'UV Protection Retro Square Sunglasses (Free Size)', 'Polarized Wayfarer Sunglasses (55)', 'UV Protection, Riding Glasses Retro Square Sunglasses (...', 'UV Protection Rectangular Sunglasses (49)', 'Mirrored Aviator Sunglasses (55)', 'UV Protection Round Sunglasses (50)', 'UV Protection Aviator Sunglasses (58)', 'UV Protection, Gradient Butterfly Sunglasses (52)', 'UV Protection Cat-eye, Wayfarer Sunglasses (Free Size)', 'UV Protection Wayfarer Sunglasses (50)', 'by Lenskart Polarized, UV Protection Wayfarer Sunglasse...', 'UV Protection Wayfarer Sunglasses (Free Size)', 'UV Protection Wayfarer Sunglasses (Free Size)', 'by Lenskart Polarized, UV Protection Round Sunglasses (...', 'Polarized Clubmaster Sunglasses (58)', 'UV Protection Rectangular Sunglasses (Free Size)', 'UV Protection Aviator Sunglasses (58)', 'UV Protection Retro Square Sunglasses (60)', 'Polarized, UV Protection Rectangular Sunglasses (55)', 'by Lenskart Polarized, UV Protection Wayfarer Sunglasse...', 'UV Protection Wayfarer Sunglasses (53)', 'UV Protection Butterfly Sunglasses (65)', 'by Lenskart Polarized, UV Protection Retro Square Sungl...', 'Polarized, UV Protection Sports Sunglasses (55)', 'Polarized, UV Protection Retro Square Sunglasses (61)', 'UV Protection Round Sunglasses (50)', 'UV Protection Sports Sunglasses (62)', 'UV Protection Round, Over-sized Sunglasses (Free Size)', 'by Lenskart Polarized, UV Protection Aviator Sunglasses...', 'Toughened Glass Lens, UV Protection Wayfarer, Rectangul...', 'by Lenskart Polarized, UV Protection Aviator Sunglasses...', 'UV Protection Wayfarer Sunglasses (Free Size)', 'Toughened Glass Lens, UV Protection Aviator Sunglasses ...', 'Polarized Butterfly Sunglasses (64)', 'UV Protection, Gradient Wayfarer, Retro Square Sunglass...', 'UV Protection Wayfarer Sunglasses (56)', 'UV Protection, Riding Glasses Rectangular Sunglasses (F...', 'UV Protection Sports, Wrap-around Sunglasses (70)', 'UV Protection, Mirrored Sports Sunglasses (62)', 'by Lenskart Polarized, UV Protection Aviator Sunglasses...', 'UV Protection Retro Square Sunglasses (57)', 'UV Protection Retro Square Sunglasses (54)', 'Polarized, Night Vision, Riding Glasses Sports, Wrap-ar...', 'UV Protection, Gradient Rectangular Sunglasses (65)', 'UV Protection, Gradient Over-sized Sunglasses (59)', 'Riding Glasses, UV Protection Clubmaster, Wayfarer Sung...', 'UV Protection Aviator Sunglasses (57)', 'Polarized, UV Protection Sports, Wrap-around Sunglasses...', 'Polarized, UV Protection Sports Sunglasses (68)', 'UV Protection, Riding Glasses Rectangular Sunglasses (F...', 'UV Protection Shield Sunglasses (Free Size)', 'by Lenskart Polarized, UV Protection Round Sunglasses (...', 'by Lenskart UV Protection Retro Square Sunglasses (50)', 'UV Protection Rectangular Sunglasses (48)', 'UV Protection, Gradient Retro Square Sunglasses (58)', 'UV Protection, Riding Glasses Rectangular Sunglasses (F...', 'by Lenskart Polarized, UV Protection Clubmaster Sunglas...']\n",
      "['₹766', '₹497', '₹399', '₹299', '₹159', '₹210', '₹699', '₹749', '₹499', '₹829', '₹459', '₹974', '₹399', '₹599', '₹169', '₹290', '₹596', '₹622', '₹297', '₹388', '₹499', '₹487', '₹749', '₹209', '₹169', '₹449', '₹499', '₹1,999', '₹269', '₹589', '₹1,599', '₹399', '₹232', '₹296', '₹699', '₹199', '₹674', '₹1,999', '₹221', '₹233', '₹1,999', '₹487', '₹779', '₹609', '₹299', '₹459', '₹639', '₹674', '₹792', '₹265', '₹1,111', '₹449', '₹199', '₹518', '₹279', '₹537', '₹664', '₹380', '₹643', '₹187', '₹559', '₹549', '₹399', '₹244', '₹579', '₹399', '₹1,169', '₹390', '₹349', '₹272', '₹559', '₹674', '₹699', '₹622', '₹251', '₹659', '₹779', '₹719', '₹441', '₹296', '₹569', '₹1,999', '₹449', '₹179', '₹346', '₹791', '₹1,388', '₹594', '₹229', '₹315', '₹674', '₹537', '₹725', '₹649', '₹709', '₹725', '₹2,499', '₹715', '₹230', '₹199', '₹412', '₹330', '₹699', '₹539', '₹411', '₹482', '₹560', '₹659', '₹340', '₹579', '₹1,049', '₹1,234', '₹199', '₹629', '₹749', '₹699', '₹487', '₹418', '₹267', '₹682']\n",
      "120\n",
      "120\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "# to print all the data and just seeing the length of all details of the sunglasses \n",
    "print(Brand)\n",
    "print(Product_Description)\n",
    "print(Price)\n",
    "print(len(Brand))\n",
    "print(len(Product_Description))\n",
    "print(len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15967038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
