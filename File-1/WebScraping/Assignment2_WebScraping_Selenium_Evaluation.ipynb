{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40a270f6",
   "metadata": {},
   "source": [
    "# Web Scraping –Evaluation- Assignment 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4deee35",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1. All the questions must be done in a single Jupyternotebook.\n",
    "2. There should be proper comments in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0110f8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in ./anaconda3/lib/python3.11/site-packages (4.18.1)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in ./anaconda3/lib/python3.11/site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in ./anaconda3/lib/python3.11/site-packages (from selenium) (0.24.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in ./anaconda3/lib/python3.11/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in ./anaconda3/lib/python3.11/site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in ./anaconda3/lib/python3.11/site-packages (from selenium) (4.10.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in ./anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in ./anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in ./anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in ./anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in ./anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in ./anaconda3/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in ./anaconda3/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in ./anaconda3/lib/python3.11/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium #Installing the selenium library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3adfb771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the webdriver for the web browser\n",
    "#Import all the required libraries\n",
    "\n",
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "#To import the Keys library for enter key\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc5c090",
   "metadata": {},
   "source": [
    "# Question 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bae65e",
   "metadata": {},
   "source": [
    "Q1: In this question you have to scrape data using the filters available on the webpage You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the web page https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad2cd94",
   "metadata": {},
   "source": [
    "1. first get the web page https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6d8cc08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()              # for just opening the google chrome webdriver\n",
    "driver.get(\"https://www.naukri.com/\")   # for opening the website(https://www.naukri.com/) in google chrome webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a7826d",
   "metadata": {},
   "source": [
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cc8abfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find element for job search bar and Enter the Data Scientist in \"Skill, Designations, and Companies” field.\n",
    "Designation_= driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "Designation_.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d6fb1f",
   "metadata": {},
   "source": [
    "3.  click the search button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6862723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find element for Search button and click the search button\n",
    "Search_button=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "Search_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1768965d",
   "metadata": {},
   "source": [
    "4.  apply the location filter \"Delhi/NCR\" and salary filter \"3-6 lakhs\" by checking the respective boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d9039d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the location filter \"Delhi/NCR\" checkbox\n",
    "Checkbox_Location=driver.find_element(By.XPATH,'/html/body/div/div/main/div[1]/div[1]/div/div/div[2]/div[4]/div[2]/div[3]/label/i')\n",
    "Checkbox_Location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e4026b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the Salary filter \"3-6 lakhs\" checkbox\n",
    "Checkbox_Salary=driver.find_element(By.XPATH,'/html/body/div/div/main/div[1]/div[1]/div/div/div[2]/div[6]/div[2]/div[2]/label/i')\n",
    "Checkbox_Salary.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83695a2f",
   "metadata": {},
   "source": [
    "5.You have to scrape the data (job-title, job-location, company name, experience required) for the first 10 jobs results you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5f7928e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "['Data Scientist', 'Data Scientist', 'Lead Data Scientist', 'Data Scientist', 'JOB Opening // Data science // Neosoft Mumbai ,Pune,noida', 'Lead Customer Success - Data Scientist', 'Data Scientist', 'Data Scientist', 'Python and ML Trainer', 'Data Scientist']\n",
      "20\n",
      "['Mumbai, Hyderabad, Gurugram', 'Gurugram, Bengaluru', 'Kolkata, Mumbai, New Delhi, Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru', 'Kolkata, Mumbai, New Delhi, Hyderabad, Pune, Chennai, Bengaluru', 'Noida, Mumbai, Pune', 'Pune, Gurugram', 'Noida', 'Noida', 'Hyderabad, New Delhi, Pune, Gurugram, Bengaluru', 'Gurugram, Bengaluru']\n",
      "20\n",
      "['Deloitte', 'Blackbuck', 'Elitefit.ai', 'Fort Technologies', 'NeoSOFT', 'ZS Associates', 'Innovaccer', 'Times Internet', 'The Scholar', 'Acenet']\n",
      "20\n",
      "['3-6 Yrs', '3-7 Yrs', '3-7 Yrs', '1-3 Yrs', '4-7 Yrs', '2-4 Yrs', '2-7 Yrs', '3-8 Yrs', '3-8 Yrs', '3-4 Yrs']\n"
     ]
    }
   ],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "#To scrap all the job-titles from the given page\n",
    "for i in driver.find_elements(By.XPATH, '//div[@class=\"srp-jobtuple-wrapper\"]/div/div/a'):\n",
    "    job_title.append(i.text)\n",
    "print(len(job_title))\n",
    "print(job_title[:10])\n",
    "\n",
    "#To scrap all the job-locations from the given page\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"locWdth\"]'):\n",
    "    job_location.append(i.text)\n",
    "print(len(job_location))   \n",
    "print(job_location[:10])\n",
    "\n",
    "#To scrap all the company-names from the given page\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\" comp-dtls-wrap\"]/a[1]'):\n",
    "    company_name.append(i.text)\n",
    "print(len(company_name))\n",
    "print(company_name[:10])\n",
    "\n",
    "#To scrap all the experience-requirements from the given page\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"expwdth\"]'):\n",
    "    experience_required.append(i.text)\n",
    "print(len(experience_required))\n",
    "print(experience_required[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b770471",
   "metadata": {},
   "source": [
    "6. Finally create a dataframe of the scraped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9b741d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 4)\n",
      "                                           Job Title  \\\n",
      "0                                     Data Scientist   \n",
      "1                                     Data Scientist   \n",
      "2                                Lead Data Scientist   \n",
      "3                                     Data Scientist   \n",
      "4  JOB Opening // Data science // Neosoft Mumbai ...   \n",
      "5             Lead Customer Success - Data Scientist   \n",
      "6                                     Data Scientist   \n",
      "7                                     Data Scientist   \n",
      "8                              Python and ML Trainer   \n",
      "9                                     Data Scientist   \n",
      "\n",
      "                                        Job Location       Company Name  \\\n",
      "0                        Mumbai, Hyderabad, Gurugram           Deloitte   \n",
      "1                                Gurugram, Bengaluru          Blackbuck   \n",
      "2  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...        Elitefit.ai   \n",
      "3  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...  Fort Technologies   \n",
      "4                                Noida, Mumbai, Pune            NeoSOFT   \n",
      "5                                     Pune, Gurugram      ZS Associates   \n",
      "6                                              Noida         Innovaccer   \n",
      "7                                              Noida     Times Internet   \n",
      "8    Hyderabad, New Delhi, Pune, Gurugram, Bengaluru        The Scholar   \n",
      "9                                Gurugram, Bengaluru             Acenet   \n",
      "\n",
      "  Experience Required  \n",
      "0             3-6 Yrs  \n",
      "1             3-7 Yrs  \n",
      "2             3-7 Yrs  \n",
      "3             1-3 Yrs  \n",
      "4             4-7 Yrs  \n",
      "5             2-4 Yrs  \n",
      "6             2-7 Yrs  \n",
      "7             3-8 Yrs  \n",
      "8             3-8 Yrs  \n",
      "9             3-4 Yrs  \n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe of the scraped data\n",
    "df=pd.DataFrame({'Job Title':job_title,'Job Location':job_location,'Company Name':company_name,'Experience Required':experience_required}) \n",
    "print(df.shape)\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfecc6e",
   "metadata": {},
   "source": [
    "# Question 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00ae04f",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the\n",
    "job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter “Data Scientist” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f7dbc0",
   "metadata": {},
   "source": [
    "1. First get the webpage https://www.shine.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8aa7f9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()              # for just opening the google chrome webdriver\n",
    "driver.get(\"https://www.shine.com/\")   # for opening the website(https://www.shine.com/) in google chrome webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37594247",
   "metadata": {},
   "source": [
    "2. Enter “Data Scientist” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f95045a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first click on job title,skills field\n",
    "First_click= driver.find_element(By.XPATH,'//input[@class=\"input\"]')\n",
    "First_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e9fca30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find element for job search bar and Enter the Data Scientist`\n",
    "Designation_= driver.find_element(By.CLASS_NAME,'form-control  ') \n",
    "Designation_.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "31c34bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find element for job location bar and Enter Bangalore\n",
    "Location_= driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input \")\n",
    "Location_.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a405a4b",
   "metadata": {},
   "source": [
    "3. click the searchbutton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ba18cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find element for Search  button and click the search button\n",
    "Search_button=driver.find_element(By.XPATH,'//button[@type=\"submit\"]')\n",
    "Search_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a96db3",
   "metadata": {},
   "source": [
    "4. You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a8bdffec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "['Data Scientist Opening', 'Data Scientist Opening', 'Data Scientist Recruitment', 'Data Scientist', 'ML Data Scientist', 'Data Scientist Urgent Vacancy', 'Data Scientist', 'Data Scientist Recruitment', 'Data Scientist Recruitment', 'Data Scientist']\n",
      "20\n",
      "['Bangalore', 'Bangalore', 'Bangalore', 'Bangalore', 'Bangalore', 'Bangalore', 'Bangalore', 'Bangalore', 'Bangalore', 'Bangalore']\n",
      "20\n",
      "['renuka interprises', 'renuka interprises', 'radhika enterprises', 'techno endura', 'gujarat facility services hiring fo...', 'renuka interprises', 'acme services private limited', 'renuka interprises', 'renuka interprises', 'ltimindtree limited']\n",
      "20\n",
      "['0 to 4 Yrs', '0 to 4 Yrs', '0 to 4 Yrs', '0 to 2 Yrs', '5 to 8 Yrs', '0 to 4 Yrs', '3 to 5 Yrs', '0 to 4 Yrs', '0 to 4 Yrs', '6 to 8 Yrs']\n"
     ]
    }
   ],
   "source": [
    "jobtitle=[]\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "#To scrap all the job-titles from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//a[starts-with(@href,\"/jobs/\")]'):\n",
    "    jobtitle.append(i.text)\n",
    "    job_title=jobtitle[2:22]\n",
    "print(len(job_title))    \n",
    "print(job_title[:10])\n",
    "\n",
    "#To scrap all the job-locations from the given page\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]'):\n",
    "    job_location.append(i.text.split(\"\\n\")[0])\n",
    "print(len(job_location))\n",
    "print(job_location[:10])\n",
    "\n",
    "#To scrap all the company-names from the given page\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]/span'):\n",
    "    company_name.append(i.text)\n",
    "print(len(company_name))\n",
    "print(company_name[:10])\n",
    "\n",
    "#To scrap all the experience-requirements from the given page\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]'):\n",
    "    experience_required.append(i.text)\n",
    "print(len(experience_required))\n",
    "print(experience_required[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c75a65",
   "metadata": {},
   "source": [
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e2d8e8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 4)\n",
      "                       Job Title Job Location  \\\n",
      "0         Data Scientist Opening    Bangalore   \n",
      "1         Data Scientist Opening    Bangalore   \n",
      "2     Data Scientist Recruitment    Bangalore   \n",
      "3                 Data Scientist    Bangalore   \n",
      "4              ML Data Scientist    Bangalore   \n",
      "5  Data Scientist Urgent Vacancy    Bangalore   \n",
      "6                 Data Scientist    Bangalore   \n",
      "7     Data Scientist Recruitment    Bangalore   \n",
      "8     Data Scientist Recruitment    Bangalore   \n",
      "9                 Data Scientist    Bangalore   \n",
      "\n",
      "                             Company Name Experience Required  \n",
      "0                      renuka interprises          0 to 4 Yrs  \n",
      "1                      renuka interprises          0 to 4 Yrs  \n",
      "2                     radhika enterprises          0 to 4 Yrs  \n",
      "3                           techno endura          0 to 2 Yrs  \n",
      "4  gujarat facility services hiring fo...          5 to 8 Yrs  \n",
      "5                      renuka interprises          0 to 4 Yrs  \n",
      "6           acme services private limited          3 to 5 Yrs  \n",
      "7                      renuka interprises          0 to 4 Yrs  \n",
      "8                      renuka interprises          0 to 4 Yrs  \n",
      "9                     ltimindtree limited          6 to 8 Yrs  \n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe of the scraped data\n",
    "df=pd.DataFrame({'Job Title':job_title,'Job Location':job_location,'Company Name':company_name,'Experience Required':experience_required}) \n",
    "print(df.shape)\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aca5c8",
   "metadata": {},
   "source": [
    "# Question 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb995b9",
   "metadata": {},
   "source": [
    "Q3: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/product-\n",
    "reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=F\n",
    "LIPKART\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews.\n",
    "Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cd238d",
   "metadata": {},
   "source": [
    "1. First get the webpage \" https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "82973c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()              # for just opening the google chrome webdriver\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\")   # for opening the flipkart website link(given) in google chrome webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96ead27",
   "metadata": {},
   "source": [
    "2. To Scrape the attributes for first 100 reviews: rating, Review summary, full review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6863d68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating=[]\n",
    "Review_Summary=[]\n",
    "Full_Review=[]\n",
    "# giving the start and end range of the pages for scraping the first 100 reviews\n",
    "start=0  # start page\n",
    "end=10    # end page\n",
    "for page in range(start,end):\n",
    "    ratings=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]') # To scrape of all 100 Rating of iphone11 from start page to end page after clicking on the next button\n",
    "    #print(len(ratings))\n",
    "    #print(ratings)\n",
    "    ReviewSummaries=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')# To scrape all 100 Review summary of iphone11 from start page to end page after clicking on the next button\n",
    "    #print(len(ReviewSummaries))\n",
    "    #print(ReviewSummaries)\n",
    "    FullReviews=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]/div[1]/div')# To scrape all 100 full review of iphone11 from start page to end page after clicking on the next button\n",
    "    #print(len(FullReviews))\n",
    "    #print(FullReviews)\n",
    "    for i in ratings:\n",
    "        Rating.append(i.text)  \n",
    "    for j in ReviewSummaries:\n",
    "        Review_Summary.append(j.text)\n",
    "    for k in FullReviews:\n",
    "        Full_Review.append(k.text)\n",
    "    # to find the element of the next button and then click on the next button\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]/span')\n",
    "    next_button.click()\n",
    "    # for giving some time delay jumping from one page to another\n",
    "    time.sleep(3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "851cf403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5']\n",
      "100\n",
      "['Worth every penny', 'Best in the market!', 'Wonderful', 'Fabulous!', 'Terrific', 'Classy product', 'Perfect product!', 'Terrific purchase', 'Just wow!', 'Brilliant', 'Must buy!', 'Brilliant', 'Awesome', 'Excellent', 'Perfect product!', 'Super!', 'Fabulous!', 'Terrific purchase', 'Must buy!', 'Highly recommended', 'Worth every penny', 'Best in the market!', 'Wonderful', 'Fabulous!', 'Terrific', 'Classy product', 'Perfect product!', 'Terrific purchase', 'Just wow!', 'Brilliant', 'Must buy!', 'Brilliant', 'Awesome', 'Excellent', 'Perfect product!', 'Super!', 'Fabulous!', 'Terrific purchase', 'Must buy!', 'Highly recommended', 'Worth every penny', 'Best in the market!', 'Wonderful', 'Fabulous!', 'Terrific', 'Classy product', 'Perfect product!', 'Terrific purchase', 'Just wow!', 'Brilliant', 'Must buy!', 'Brilliant', 'Awesome', 'Excellent', 'Perfect product!', 'Super!', 'Fabulous!', 'Terrific purchase', 'Must buy!', 'Highly recommended', 'Worth every penny', 'Best in the market!', 'Wonderful', 'Fabulous!', 'Terrific', 'Classy product', 'Perfect product!', 'Terrific purchase', 'Just wow!', 'Brilliant', 'Must buy!', 'Brilliant', 'Awesome', 'Excellent', 'Perfect product!', 'Super!', 'Fabulous!', 'Terrific purchase', 'Must buy!', 'Highly recommended', 'Worth every penny', 'Best in the market!', 'Wonderful', 'Fabulous!', 'Terrific', 'Classy product', 'Perfect product!', 'Terrific purchase', 'Just wow!', 'Brilliant', 'Must buy!', 'Brilliant', 'Awesome', 'Excellent', 'Perfect product!', 'Super!', 'Fabulous!', 'Terrific purchase', 'Must buy!', 'Highly recommended']\n",
      "100\n",
      "['Feeling awesome after getting the delivery of my phone. Dual speakers makes the sound quality very loud. Amazing!!', 'Good Camera', 'This is amazing at all', 'Super🔥 and good performance 👌❤️', 'Very very good', 'Camera is awesome\\nBest battery backup\\nA performer 👌🏻\\nIt will be a real value for money if they provide charger and earphone inbox!', 'Photos super', 'Value for money 😍', 'Perfect Product!!', 'very good camera quality', 'It’s really awesome', 'Excellent Phone.', 'iPhone 11 is a good phone. Not a very big difference between 12 except for the OLED screen and a very minor camera improvement which is you cant make a difference. If you are planning for a iPhone and you have budget you definitely can go for this without second thoughts.\\nNow some people are complaining and giving review 0 or so because there is no charger and headphones, but thats been already mentioned so I assume they are illiterate. Its not that Flipkart is removing them duh. Anyways bee...', 'NYC', 'V Good all', 'Good product 👌I love iPhone', 'It’s very good battery life and display and video quality and ther performance of iPhone.....🔥🔥🌈', 'Value for money 🖤🖤', 'Go for iPhone 11 , if confused between iPhone 11 or iPhone 12 mini.Battery Life is enhanced , it worked for complete 2 days without charging it. Explored new features of taking screenshot by clicking on apple logo by Haptic Touch , Portrait mode with stage effect enhanced & slow motion selfie.', 'Awesome Battery Life...Camera clarity is too good..\\nValue for money...Its gives full day battery backup in single charge...', 'Feeling awesome after getting the delivery of my phone. Dual speakers makes the sound quality very loud. Amazing!!', 'Good Camera', 'This is amazing at all', 'Super🔥 and good performance 👌❤️', 'Very very good', 'Camera is awesome\\nBest battery backup\\nA performer 👌🏻\\nIt will be a real value for money if they provide charger and earphone inbox!', 'Photos super', 'Value for money 😍', 'Perfect Product!!', 'very good camera quality', 'It’s really awesome', 'Excellent Phone.', 'iPhone 11 is a good phone. Not a very big difference between 12 except for the OLED screen and a very minor camera improvement which is you cant make a difference. If you are planning for a iPhone and you have budget you definitely can go for this without second thoughts.\\nNow some people are complaining and giving review 0 or so because there is no charger and headphones, but thats been already mentioned so I assume they are illiterate. Its not that Flipkart is removing them duh. Anyways bee...', 'NYC', 'V Good all', 'Good product 👌I love iPhone', 'It’s very good battery life and display and video quality and ther performance of iPhone.....🔥🔥🌈', 'Value for money 🖤🖤', 'Go for iPhone 11 , if confused between iPhone 11 or iPhone 12 mini.Battery Life is enhanced , it worked for complete 2 days without charging it. Explored new features of taking screenshot by clicking on apple logo by Haptic Touch , Portrait mode with stage effect enhanced & slow motion selfie.', 'Awesome Battery Life...Camera clarity is too good..\\nValue for money...Its gives full day battery backup in single charge...', 'Feeling awesome after getting the delivery of my phone. Dual speakers makes the sound quality very loud. Amazing!!', 'Good Camera', 'This is amazing at all', 'Super🔥 and good performance 👌❤️', 'Very very good', 'Camera is awesome\\nBest battery backup\\nA performer 👌🏻\\nIt will be a real value for money if they provide charger and earphone inbox!', 'Photos super', 'Value for money 😍', 'Perfect Product!!', 'very good camera quality', 'It’s really awesome', 'Excellent Phone.', 'iPhone 11 is a good phone. Not a very big difference between 12 except for the OLED screen and a very minor camera improvement which is you cant make a difference. If you are planning for a iPhone and you have budget you definitely can go for this without second thoughts.\\nNow some people are complaining and giving review 0 or so because there is no charger and headphones, but thats been already mentioned so I assume they are illiterate. Its not that Flipkart is removing them duh. Anyways bee...', 'NYC', 'V Good all', 'Good product 👌I love iPhone', 'It’s very good battery life and display and video quality and ther performance of iPhone.....🔥🔥🌈', 'Value for money 🖤🖤', 'Go for iPhone 11 , if confused between iPhone 11 or iPhone 12 mini.Battery Life is enhanced , it worked for complete 2 days without charging it. Explored new features of taking screenshot by clicking on apple logo by Haptic Touch , Portrait mode with stage effect enhanced & slow motion selfie.', 'Awesome Battery Life...Camera clarity is too good..\\nValue for money...Its gives full day battery backup in single charge...', 'Feeling awesome after getting the delivery of my phone. Dual speakers makes the sound quality very loud. Amazing!!', 'Good Camera', 'This is amazing at all', 'Super🔥 and good performance 👌❤️', 'Very very good', 'Camera is awesome\\nBest battery backup\\nA performer 👌🏻\\nIt will be a real value for money if they provide charger and earphone inbox!', 'Photos super', 'Value for money 😍', 'Perfect Product!!', 'very good camera quality', 'It’s really awesome', 'Excellent Phone.', 'iPhone 11 is a good phone. Not a very big difference between 12 except for the OLED screen and a very minor camera improvement which is you cant make a difference. If you are planning for a iPhone and you have budget you definitely can go for this without second thoughts.\\nNow some people are complaining and giving review 0 or so because there is no charger and headphones, but thats been already mentioned so I assume they are illiterate. Its not that Flipkart is removing them duh. Anyways bee...', 'NYC', 'V Good all', 'Good product 👌I love iPhone', 'It’s very good battery life and display and video quality and ther performance of iPhone.....🔥🔥🌈', 'Value for money 🖤🖤', 'Go for iPhone 11 , if confused between iPhone 11 or iPhone 12 mini.Battery Life is enhanced , it worked for complete 2 days without charging it. Explored new features of taking screenshot by clicking on apple logo by Haptic Touch , Portrait mode with stage effect enhanced & slow motion selfie.', 'Awesome Battery Life...Camera clarity is too good..\\nValue for money...Its gives full day battery backup in single charge...', 'Feeling awesome after getting the delivery of my phone. Dual speakers makes the sound quality very loud. Amazing!!', 'Good Camera', 'This is amazing at all', 'Super🔥 and good performance 👌❤️', 'Very very good', 'Camera is awesome\\nBest battery backup\\nA performer 👌🏻\\nIt will be a real value for money if they provide charger and earphone inbox!', 'Photos super', 'Value for money 😍', 'Perfect Product!!', 'very good camera quality', 'It’s really awesome', 'Excellent Phone.', 'iPhone 11 is a good phone. Not a very big difference between 12 except for the OLED screen and a very minor camera improvement which is you cant make a difference. If you are planning for a iPhone and you have budget you definitely can go for this without second thoughts.\\nNow some people are complaining and giving review 0 or so because there is no charger and headphones, but thats been already mentioned so I assume they are illiterate. Its not that Flipkart is removing them duh. Anyways bee...', 'NYC', 'V Good all', 'Good product 👌I love iPhone', 'It’s very good battery life and display and video quality and ther performance of iPhone.....🔥🔥🌈', 'Value for money 🖤🖤', 'Go for iPhone 11 , if confused between iPhone 11 or iPhone 12 mini.Battery Life is enhanced , it worked for complete 2 days without charging it. Explored new features of taking screenshot by clicking on apple logo by Haptic Touch , Portrait mode with stage effect enhanced & slow motion selfie.', 'Awesome Battery Life...Camera clarity is too good..\\nValue for money...Its gives full day battery backup in single charge...']\n",
      "100\n",
      "(100, 3)\n",
      "   Rating       Review_Summary  \\\n",
      "0       5    Worth every penny   \n",
      "1       5  Best in the market!   \n",
      "2       5            Wonderful   \n",
      "3       5            Fabulous!   \n",
      "4       5             Terrific   \n",
      "..    ...                  ...   \n",
      "95      5               Super!   \n",
      "96      5            Fabulous!   \n",
      "97      5    Terrific purchase   \n",
      "98      5            Must buy!   \n",
      "99      5   Highly recommended   \n",
      "\n",
      "                                          Full_Review  \n",
      "0   Feeling awesome after getting the delivery of ...  \n",
      "1                                         Good Camera  \n",
      "2                              This is amazing at all  \n",
      "3                     Super🔥 and good performance 👌❤️  \n",
      "4                                      Very very good  \n",
      "..                                                ...  \n",
      "95                        Good product 👌I love iPhone  \n",
      "96  It’s very good battery life and display and vi...  \n",
      "97                                 Value for money 🖤🖤  \n",
      "98  Go for iPhone 11 , if confused between iPhone ...  \n",
      "99  Awesome Battery Life...Camera clarity is too g...  \n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# to print all the data and just seeing the length of all 100 review details of iphone11. \n",
    "print(Rating)\n",
    "print(len(Rating))\n",
    "\n",
    "print(Review_Summary)\n",
    "print(len(Review_Summary))\n",
    "\n",
    "print(Full_Review)\n",
    "print(len(Full_Review))\n",
    "\n",
    "#creating a dataframe of the scraped data\n",
    "df=pd.DataFrame({'Rating':Rating,'Review_Summary':Review_Summary,'Full_Review':Full_Review}) \n",
    "print(df.shape)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c214ce",
   "metadata": {},
   "source": [
    "# Question 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c29de5",
   "metadata": {},
   "source": [
    "Q4: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search\n",
    "field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "\n",
    "As shown in the below image, you have to scrape the above attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad827b5",
   "metadata": {},
   "source": [
    "1. first visit to website and get the webpage \"https://www.flipkart.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "41bf6c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()              # for just opening the google chrome webdriver\n",
    "driver.get(\"https://www.flipkart.com/\")   # for opening the flipkart website link(given) in google chrome webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2e060629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first click on search field\n",
    "First_click= driver.find_element(By.XPATH,'//input[@class=\"Pke_EE\"]')\n",
    "First_click.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6fad1f",
   "metadata": {},
   "source": [
    "2. Search the Sneakers by entering “Sneakers” in search field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c18fd25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find element for Sneakers in search field and Enter the Sneakers`\n",
    "Search_Element= driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div/div/div[1]/div[1]/header/div[1]/div[2]/form/div/div/input') \n",
    "Search_Element.send_keys(\"Sneakers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb9b94a",
   "metadata": {},
   "source": [
    "3. Click on the Search Button "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f85d2f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# After entering the sneakers,just pressing the Enter key \n",
    "Search_Element.send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe854df",
   "metadata": {},
   "source": [
    "2. To Scrape the 3 attributes of each sneaker for first 100 sneakers: Brand, Product Description, Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5e51b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "SneakerBrand=[]\n",
    "SneakerProductDescription=[]\n",
    "SneakerPrice=[]\n",
    "# giving the start and end range of the pages for scraping the first 100 Sneakers details\n",
    "start=0  # start page\n",
    "end=3    # end page\n",
    "for page in range(start,end):\n",
    "    BrandNames=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]') # To scrape of all 100 sneaker's brand names from start page to end page after clicking on the next button\n",
    "    #print(len(BrandNames))\n",
    "    #print(BrandNames)\n",
    "    ProductDescription=driver.find_elements(By.XPATH,'//a[contains(@class,\"IRpwTa\")]')# To scrape all 100 sneaker's ProductDescription from start page to end page after clicking on the next button\n",
    "    #print(len(ProductDescription))\n",
    "    #print(ProductDescription)\n",
    "    Price=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\" or @class=\"_3utEwz\"]')# To scrape all 100 sneaker's Price from start page to end page after clicking on the next button\n",
    "    #print(len(Price))\n",
    "    #print(Price)\n",
    "    for i in BrandNames:\n",
    "        SneakerBrand.append(i.text)  \n",
    "    for j in  ProductDescription:\n",
    "        SneakerProductDescription.append(j.text)\n",
    "    for k in Price:\n",
    "        #Sneaker_Price.append(k.text)\n",
    "        SneakerPrice.append(k.text.replace(\"₹\",\"\"))\n",
    "    # to find the element of the next button and then click on the next button\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]/span')\n",
    "    next_button.click()\n",
    "    # for giving some time delay jumping from one page to another\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "697135c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asian', 'ATOM', 'URBANBOX', 'Deals4you', 'RED TAPE', 'PUMA', 'RUN SEVEN', 'RED TAPE', 'A-CLASS', 'BIRDE', 'RUN SEVEN', 'lejano', 'BIRDE', 'RED TAPE', 'A-CLASS', 'RED TAPE', 'asian', 'asian', 'BIRDE', 'A-CLASS', 'PUMA', 'RED TAPE', 'aadi', 'Labbin', 'PUMA', 'Ego by NS', 'PUMA', 'asian', 'BERSACHE', 'Mzzideko', 'RED TAPE', 'RED TAPE', 'asian', 'BIRDE', 'RED TAPE', 'A-CLASS', 'RUN SEVEN', 'RUN SEVEN', 'PUMA', 'BRUTON', 'RED TAPE', 'BERSACHE', 'HIGHLANDER', 'asian', 'PUMA', 'WOODLAND', 'RUN SEVEN', 'MOZAFIA', 'BIRDE', 'VENDOZ', 'asian', 'asian', 'BIRDE', 'VENDOZ', 'Shozie', 'HOTSTYLE', 'ADIDAS', 'RED TAPE', 'Layasa', 'RapidBox', 'PUMA', 'PUMA', 'RED TAPE', 'PUMA', 'asian', 'CAMPUS', 'PUMA', 'RUN SEVEN', 'HOTSTYLE', 'CLYMB', 'asian', 'PUMA', 'RED TAPE', 'Layasa', 'PUMA', 'PUMA', 'UNDER ARMOUR', 'UNDER ARMOUR', 'Deals4you', 'U.S. POLO ASSN.', 'asian', 'ATOM', 'URBANBOX', 'Deals4you', 'RED TAPE', 'PUMA', 'RUN SEVEN', 'RED TAPE', 'A-CLASS', 'BIRDE', 'RUN SEVEN', 'lejano', 'BIRDE', 'RED TAPE', 'A-CLASS', 'RED TAPE', 'asian', 'RED TAPE', 'BIRDE', 'A-CLASS', 'BERSACHE', 'asian', 'aadi', 'Labbin', 'PUMA', 'Ego by NS', 'PUMA', 'RED TAPE', 'BERSACHE', 'Mzzideko', 'asian', 'PUMA', 'asian', 'BIRDE', 'RED TAPE', 'A-CLASS', 'RED TAPE', 'RED TAPE', 'PUMA', 'BRUTON']\n",
      "120\n",
      "['Tarzan-03 Black Sneakers,Canvas,Loafers,Stylish Sneaker...', 'Alpha Predator Sneakers For Men', 'Trending Stylish Casual Outdoor Shoes Sneakers For Men', 'Sneakers For Women', 'Casual Sneakers Shoes for Men | Soft Cushioned Insole, ...', 'Fire Run V1 Sneakers For Men', '( by GO21 ) Soft Insole, Slip-Resistance|Walking Casual...', 'Casual Sneaker Shoes for Women | Soft Cushioned Insole,...', 'Trendy & Stylish Casual Shoes Sneakers For Men', 'Premium Casual Shoes for Women Sneakers For Women', '( by GO21 ) Soft Insole, Slip-Resistance|Walking Casual...', 'Sneakers For Men', 'Premium Men Casual Shoes For Men Pack Of 2 Sneakers For...', 'Sneaker Casual Shoes For Men | Soft Cushion Insole, Sli...', 'Trendy & Stylish Casual Shoes Sneakers For Men', 'Casual Sneakers Shoes for Men | Soft Cushioned Insole, ...', 'Tarzan-01 White Sneakers,Casuals,Walking,Stylish Extra ...', 'Sneaker Casual Shoes For Men | Soft Cushion Insole, Sli...', 'Combo Pack of 2 Casual Shoes Sneakers For Men', 'Trendy & Stylish Casual Shoes Sneakers For Men', 'Shuffle Ultra Sneakers For Men', 'Sneakers For Women', 'Synthetic Leather |Lightweight|Comfort|Summer|Trendy|Wa...', 'Casual Sneakers ColourFul Block Shoes For Boys And Men ...', 'Seattle Sneakers For Men', 'Sneakers For Men', 'Alfarun Sneakers For Men', 'Carnival-02 Mens High Top Casual Chunky Sneakers For Me...', 'Combo pack of 2 shoes for men Sneakers For Men', 'mzzideko sports shoe Sneakers For Men', 'Casual Sneaker Shoes for Women | Soft Cushioned Insole,...', 'Casual Sneaker Shoes For Women | Elegant White and Gree...', 'Boston-01 Chunky Sneakers,Loafers,Walking Shoes Sneaker...', 'Combo Pack of 2 Casual Shoes Sneakers For Men', 'Sneaker Casual Shoes For Men | Soft Cushion Insole, Sli...', 'Trendy & Stylish Casual Shoes Sneakers For Men', '( by GO21 ) Soft Insole, Slip-Resistance|Walking Casual...', '( by GO21 ) Soft Insole, Slip-Resistance|Walking Casual...', 'Seattle Sneakers For Men', 'Canvas shoes for Men Sneakers For Men', 'Sneaker Casual Shoes For Women | Soft Cushion Insole, S...', ', Loafers ,Casual With Extra Comfort Sneakers For Men', 'Sneakers For Men', 'Carnival-02 Mens High Top Casual Chunky Sneakers For Me...', 'Shuffle Ultra Sneakers For Men', 'Sneakers For Men', '( by GO21 ) Soft Insole, Slip-Resistance|Walking Casual...', 'Comfortable Canvas Lace-up Casual Ankle Length Sneakers...', 'Premium Sports Shoes For Men Pack Of 2 Sneakers For Men', 'Casual Stylish Trending Sneakers For Women', 'SM-162 Black Walking ,Training,Sneakers,Loafers,Canvas,...', 'Sneaker Casual Shoes for Men | Soft Cushioned Insole, S...', 'Premium Casual Shoes for Women Sneakers For Women', 'HIGH HEEL SHOES Sneakers For Women', 'Stylish Sneakers Shoes for Women And Girls Sneakers For...', 'Sports Shoes , Walking Shoes , Gym & Training Shoes And...', 'GRAND COURT BASE 3.0 M Sneakers For Men', 'Casual Sneaker Shoes For Women | Stylish and Comfortabl...', 'Casual White Shoes For Girls And Sneakers For Women', 'Sneakers For Men', 'X-Ray Speed Sneakers For Men', 'Future Rider New Core Sneakers For Men', 'Sneaker Casual Shoes for Men | Soft Cushioned Insole, S...', 'Ferrari Electron E Pro Sneakers For Men', 'Flat Sole Sneakers Shoes for all Day wear with Memory C...', 'OG-D4 Sneakers For Men', 'Morgan SL V1 Sneakers For Men', 'Sneakers For Men', 'FAST Trendy Sneakers For Men', 'Sneakers For Men', 'Carnival-02 Mens High Top Casual Chunky Fashion Sneaker...', 'Smash 3.0 Sneakers For Men', 'Casual Sneaker Shoes for Men | Soft Cushioned Insole, S...', 'Stylish Casual Sports Shoe Sneakers Sneakers For Women', 'Seattle Sneakers For Men', 'Firefly Sneakers For Men', 'Sneakers For Men', 'Sneakers For Men', 'Sneakers For Women', 'PANAL Sneakers For Men', 'Tarzan-03 Black Sneakers,Canvas,Loafers,Stylish Sneaker...', 'Alpha Predator Sneakers For Men', 'Trending Stylish Casual Outdoor Shoes Sneakers For Men', 'Sneakers For Women', 'Casual Sneakers Shoes for Men | Soft Cushioned Insole, ...', 'Fire Run V1 Sneakers For Men', '( by GO21 ) Soft Insole, Slip-Resistance|Walking Casual...', 'Casual Sneaker Shoes for Women | Soft Cushioned Insole,...', 'Trendy & Stylish Casual Shoes Sneakers For Men', 'Premium Casual Shoes for Women Sneakers For Women', '( by GO21 ) Soft Insole, Slip-Resistance|Walking Casual...', 'Sneakers For Men', 'Premium Men Casual Shoes For Men Pack Of 2 Sneakers For...', 'Sneaker Casual Shoes For Men | Soft Cushion Insole, Sli...', 'Trendy & Stylish Casual Shoes Sneakers For Men', 'Casual Sneakers Shoes for Men | Soft Cushioned Insole, ...', 'Tarzan-01 White Sneakers,Casuals,Walking,Stylish Extra ...', 'Sneaker Casual Shoes For Women | Soft Cushion Insole, S...', 'Combo Pack of 2 Casual Shoes Sneakers For Men', 'Trendy & Stylish Casual Shoes Sneakers For Men', ', Loafers ,Casual With Extra Comfort Sneakers For Men', 'Sneaker Casual Shoes For Men | Soft Cushion Insole, Sli...', 'Synthetic Leather |Lightweight|Comfort|Summer|Trendy|Wa...', 'Casual Sneakers ColourFul Block Shoes For Boys And Men ...', 'Seattle Sneakers For Men', 'Sneakers For Men', 'Shuffle Ultra Sneakers For Men', 'Sneakers For Women', 'Combo pack of 2 shoes for men Sneakers For Men', 'mzzideko sports shoe Sneakers For Men', 'Carnival-02 Mens High Top Casual Chunky Sneakers For Me...', 'Alfarun Sneakers For Men', 'Boston-01 Chunky Sneakers,Loafers,Walking Shoes Sneaker...', 'Combo Pack of 2 Casual Shoes Sneakers For Men', 'Sneaker Casual Shoes For Men | Soft Cushion Insole, Sli...', 'Trendy & Stylish Casual Shoes Sneakers For Men', 'Casual Sneaker Shoes for Women | Soft Cushioned Insole,...', 'Casual Sneaker Shoes For Women | Elegant White and Gree...', 'Seattle Sneakers For Men', 'Canvas shoes for Men Sneakers For Men']\n",
      "120\n",
      "['688', '1,408', '299', '439', '1,179', '1,047', '1,073', '1,459', '499', '299', '1,073', '443', '549', '1,079', '499', '1,179', '700', '746', '544', '499', '1,699', '1,099', '299', '539', '1,381', '291', '2,149', '982', 'Price: Not Available', '489', '1,019', '1,139', '769', '549', '1,079', '499', '1,050', '1,050', '1,379', '295', '1,379', '1,281', '629', '982', '1,699', '1,789', '1,050', '679', '575', '569', '631', '688', '299', '499', '399', '259', '3,167', '1,139', '434', '633', '3,359', '3,599', '1,379', '2,182', '963', '649', '1,799', '1,050', '342', '421', '982', '1,707', '1,579', '449', '1,390', '1,270', '5,499', '3,999', '439', '1,189', '688', '1,408', '299', '439', '1,179', '1,047', '1,073', '1,459', '499', '299', '1,073', '443', '549', '1,079', '499', '1,179', '700', '1,379', '544', '499', '1,281', '746', '299', '539', '1,381', '291', '1,699', '1,099', 'Price: Not Available', '489', '982', '2,149', '769', '549', '1,079', '499', '1,019', '1,139', '1,379', '295']\n",
      "120\n",
      "(120, 3)\n",
      "    Brand Names                                Product Description Price (₹)\n",
      "0         asian  Tarzan-03 Black Sneakers,Canvas,Loafers,Stylis...       688\n",
      "1          ATOM                    Alpha Predator Sneakers For Men     1,408\n",
      "2      URBANBOX  Trending Stylish Casual Outdoor Shoes Sneakers...       299\n",
      "3     Deals4you                                 Sneakers For Women       439\n",
      "4      RED TAPE  Casual Sneakers Shoes for Men | Soft Cushioned...     1,179\n",
      "..          ...                                                ...       ...\n",
      "115     A-CLASS     Trendy & Stylish Casual Shoes Sneakers For Men       499\n",
      "116    RED TAPE  Casual Sneaker Shoes for Women | Soft Cushione...     1,019\n",
      "117    RED TAPE  Casual Sneaker Shoes For Women | Elegant White...     1,139\n",
      "118        PUMA                           Seattle Sneakers For Men     1,379\n",
      "119      BRUTON              Canvas shoes for Men Sneakers For Men       295\n",
      "\n",
      "[120 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# to print all the data and just seeing the length of all 100 sneaker's details. \n",
    "print(SneakerBrand)\n",
    "print(len(SneakerBrand))\n",
    "\n",
    "print(SneakerProductDescription)\n",
    "print(len(SneakerProductDescription))\n",
    "\n",
    "print(SneakerPrice)\n",
    "print(len(SneakerPrice))\n",
    "\n",
    "#creating a dataframe of the scraped data\n",
    "df=pd.DataFrame({'Brand Names':SneakerBrand,'Product Description':SneakerProductDescription,'Price (₹)':SneakerPrice}) \n",
    "print(df.shape)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41b1f99",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9079de3",
   "metadata": {},
   "source": [
    "Q5: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU\n",
    "Type filter to “Intel Core i7” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace628b6",
   "metadata": {},
   "source": [
    "1. first visit to website and get the webpage \"https://www.amazon.in/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "eda3e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()              # for just opening the google chrome webdriver\n",
    "driver.get(\"https://www.amazon.in/\")   # for opening the amazon website link(given) in google chrome webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "153d8b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first click on search field\n",
    "First_click= driver.find_element(By.XPATH,'//input[@type=\"text\"]')\n",
    "First_click.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12579121",
   "metadata": {},
   "source": [
    "2. Search the Sneakers by entering “Laptop” in search field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "af17d894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find element for Laptop in search field and Enter the Laptop`\n",
    "Search_Element= driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input') \n",
    "Search_Element.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902afd47",
   "metadata": {},
   "source": [
    "3. Click on the Search Button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "def82cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find element for Search  button and click the search button\n",
    "Search_button=driver.find_element(By.XPATH,'//input[@type=\"submit\"]')\n",
    "Search_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca324b1",
   "metadata": {},
   "source": [
    "4.  apply the CPU type filter \"intel core i7\" by checking the respective box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "71b54fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the CPU type filter \"intel core i7 checkbox\n",
    "\n",
    "Checkbox_CPUType=driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[19]/span/span[9]/li/span/a/div/label/i')\n",
    "\n",
    "Checkbox_CPUType.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5992159",
   "metadata": {},
   "source": [
    "5. scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "Title\n",
    "Ratings\n",
    "Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36802945",
   "metadata": {},
   "source": [
    "(i) for scraping the \"title\" of Laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "e2fa02ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "['HP Pavilion X360 11th Gen Intel Core i7 14\" (35.6cm) FHD Multitouch 2in1 Laptop (16Gb Ram/512Gb Ssd/B&O/Win 11 Home/FPR/Backlit Kb/Intel Iris Xe Graphics/Pen/Alexa/Ms Office/Silver/1.52Kg)14-Dy1047Tu', 'MSI Modern 14, Intel 12th Gen. i7-1255U, 36CM FHD 60Hz Laptop (16GB/512GB NVMe SSD/Windows 11 Home/Intel Iris Xe Graphics/Classic Black/1.4Kg), C12M-459IN', 'Lenovo IdeaPad Slim 3 Intel Core i7 12th Gen 15.6 inch (39.62cm) FHD Thin & Light Laptop (16GB/512GB SSD/Windows 11/Office 2021/3months Game Pass/Arctic Grey/1.63Kg), 82RK011EIN', 'Lenovo Yoga Slim7 Carbon Intel Evo i7 1260P 13.3\"(33.78cm) QHD 400Nit Touch Laptop(16GB/1TB SSD/Win 11/Office 2021/Backlit KB/IR Cam/3Yr Warranty/Alexa/3 Month Game Pass/Moon White/ 1kg),82U90080IN', 'ASUS TUF Gaming F15, 15.6\"(39.62 cms) FHD 144Hz, Intel Core i7-11800H 11th Gen, 4GB NVIDIA GeForce RTX 3050 Ti, Gaming Laptop (16GB/1TB SSD/Win 11/MSO/90WHrs Battery/Black/2.30 Kg), FX506HE-HN385WS', 'ASUS Vivobook 15, Intel Core i7-12650H 12th Gen, 15.6\" (39.62 cm) FHD, Thin and Light Laptop (16GB/512GB/Win11/Office 2021/Blue/1.7 kg), X1502ZA-EJ741WS', 'HP Envy 13 x360 Laptop 12th Gen Intel Evo i7-1250U 13.3inch(33.8cm) OLED Corning Gorilla Glass Touchscreen(16GB RAM/512GB SSD/B&O/Win11/5MP IR Camera/Intel Iris Xe Graphics/MSO/Alexa/Pen, 13-bf0141tu', 'Acer Travelmate Business Laptop Intel Core i7-11th Gen (Windows 11 Home/16 GB Ram/1TB SSD/Intel Iris Xe Graphics/14.0 IPS Display/Backlit Keyboard/Fingerprint Sensor) TMP214-53', 'Lenovo IdeaPad Slim 5 Intel Core i7 13700H 16\" (40.6cm) 2.5K IPS 350Nits Laptop (16GB/1TB SSD/Win 11/Office 2021/Backlit KB/FHD 1080p +IR Camera/Alexa/3 Month Game Pass/Cloud Grey/1.9Kg), 82XF0078IN', 'Dell Inspiron 5430 Laptop, 13th Gen Intel Core i7-1360P Processor/16GB/1TB SSD/14.0\" (35.56cm) FHD+ WVA 250 nits/Backlit KB + FPR/Win 11 + MSO\\'21/15 Month McAfee/Platinum Silver/Thin & Light- 1.59kg']\n"
     ]
    }
   ],
   "source": [
    "Laptop_Title=[]\n",
    "#To scrap all the Laptop-titles from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]'):   \n",
    "    Laptop_Title.append(i.text)\n",
    "print(len(Laptop_Title))    \n",
    "print(Laptop_Title[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b2ee98",
   "metadata": {},
   "source": [
    "(ii) for scraping the \"Ratings\" of Laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "4d70a8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To scrap all the Laptop-Ratings from the given page\n",
    "\n",
    "LaptopRatings=[]\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "# Locate the element to perform the hover action on\\\n",
    "element_to_hover=driver.find_element(By.XPATH,'//i[@class=\"a-icon a-icon-star-small a-star-small-4 aok-align-bottom\"]')\n",
    "actions = ActionChains(driver)\n",
    "actions.move_to_element(element_to_hover).perform()\n",
    "time.sleep(3)\n",
    "\n",
    "    #j=driver.find_element(By.XPATH,'//span[@class=\"a-icon-alt\"]')\n",
    "    #LaptopRatings.append(j.text)\n",
    "#print(len(LaptopRatings))    \n",
    "#print(LaptopRatings[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b70e6f0",
   "metadata": {},
   "source": [
    "(iii) for scraping the \"price\" of Laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "c80cf280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "['66,990', '52,010', '62,490', '1,19,990', '74,990', '64,990', '1,04,990', '49,990', '89,190', '86,730']\n"
     ]
    }
   ],
   "source": [
    "Laptop_Price=[]\n",
    "#To scrap all the Laptop-titles from the given page \n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"a-row\"]/a/span/span[2]/span[2]'):   \n",
    "    Laptop_Price.append(i.text)\n",
    "print(len(Laptop_Price))    \n",
    "print(Laptop_Price[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8b122b",
   "metadata": {},
   "source": [
    "# Question 6:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20788bd7",
   "metadata": {},
   "source": [
    "Q6: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "1. First get the webpagehttps://www.azquotes.com/\n",
    "2. Click on Top Quote\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d61ed4e",
   "metadata": {},
   "source": [
    "1. First get the webpagehttps://www.azquotes.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "02ad8e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()              # for just opening the google chrome webdriver\n",
    "driver.get(\"https://www.azquotes.com/\")   # for opening the amazon website link(given) in google chrome webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6459500f",
   "metadata": {},
   "source": [
    "2. Click on Top Quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "32ad02c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First click on Top Quote\n",
    "Click_Top_Quotes= driver.find_element(By.XPATH,'//a[contains(@href,\"/top_quotes.html\")]')\n",
    "Click_Top_Quotes.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14567c7",
   "metadata": {},
   "source": [
    "3. then scrap 1000 Quotes of all time with these following attributes: a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "8df74e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "Quote=[]\n",
    "Author=[]\n",
    "Types_Of_Quotes=[]\n",
    "\n",
    "# giving the start and end range of the pages for scraping the 1000 Quotes details\n",
    "start=0  # start page\n",
    "end=10    # end page\n",
    "for page in range(start,end):\n",
    "    Quotes=driver.find_elements(By.XPATH,'//a[@class=\"title\"]') # To scrape of all 1000 Quotes from start page to end page after clicking on the next button\n",
    "    print(len(Quotes))\n",
    "    #print(Quotes)\n",
    "    Author_name=driver.find_elements(By.XPATH,'//div[@class=\"author\"]/a') # To scrape all 1000 Quotes from start page to end page after clicking on the next button\n",
    "    print(len(Author_name))\n",
    "    #print(ProductDescription)\n",
    "    TypesOfQuotes=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')# To scrape all 1000 Quotes from start page to end page after clicking on the next button\n",
    "    print(len(TypesOfQuotes))\n",
    "    #print(Price)\n",
    "    for i in Quotes:\n",
    "        Quote.append(i.text)\n",
    "    #print(Quote)\n",
    "    for j in  Author_name:\n",
    "        Author.append(j.text)\n",
    "    #print(Author)\n",
    "    for k in TypesOfQuotes:\n",
    "        Types_Of_Quotes.append(k.text)\n",
    "    #print(Types_Of_Quotes)\n",
    "    \n",
    "    # to find the element of the next button and then click on the next button\n",
    "    next_button=driver.find_element(By.XPATH,'//a[contains(@href,\"top_quotes.html?\")]')\n",
    "    next_button.click()\n",
    "    # for giving some time delay jumping from one page to another\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "72ae9be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000 1000\n"
     ]
    }
   ],
   "source": [
    "#checking the length of each of the list\n",
    "print(len(Quote),len(Author),len(Types_Of_Quotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "7447e23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n",
      "                                                 Quote         Author Name  \\\n",
      "0    The essence of strategy is choosing what not t...      Michael Porter   \n",
      "1    One cannot and must not try to erase the past ...          Golda Meir   \n",
      "2    Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
      "3    Death is something inevitable. When a man has ...      Nelson Mandela   \n",
      "4    You have to love a nation that celebrates its ...        Erma Bombeck   \n",
      "..                                                 ...                 ...   \n",
      "995  Discipline is the bridge between goals and acc...            Jim Rohn   \n",
      "996                   Don't find fault, find a remedy.          Henry Ford   \n",
      "997  I used to think the worst thing in life was to...      Robin Williams   \n",
      "998  Friends and good manners will carry you where ...     Margaret Walker   \n",
      "999  If you want to make a permanent change, stop f...        T. Harv Eker   \n",
      "\n",
      "                               Types Of Quote  \n",
      "0    Essence, Deep Thought, Transcendentalism  \n",
      "1                   Inspiration, Past, Trying  \n",
      "2                         Country, Peace, War  \n",
      "3          Inspirational, Motivational, Death  \n",
      "4                4th Of July, Food, Patriotic  \n",
      "..                                        ...  \n",
      "995         Inspirational, Life, Motivational  \n",
      "996     Inspirational, Motivational, Positive  \n",
      "997                        Love, Life, Lonely  \n",
      "998           Love, Inspirational, Friendship  \n",
      "999          Inspirational, Change, Inspiring  \n",
      "\n",
      "[1000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe of the scraped data\n",
    "df=pd.DataFrame({'Quote':Quote,'Author Name':Author,'Types Of Quote':Types_Of_Quotes}) \n",
    "print(df.shape)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dd7437",
   "metadata": {},
   "source": [
    "# Updated link of Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7d2ad9",
   "metadata": {},
   "source": [
    "updated Q3: Scrape 100 reviews data from flipkart.com for iphone15 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-15-black-128-gb/p/itm6ac6485515ae4?pid=MOBGTAGPTB3VS24W&lid=LSTMOBGTAGPTB3VS24WVZNSC6&marketplace=FLIPKART&q=iphone+15&store=tyy/4io&srno=s_1_2&otracker=AS_QueryStore_OrganicAutoSuggest_1_2_na_na_na&otracker1=AS_QueryStore_OrganicAutoSuggest_1_2_na_na_na&fm=organic&iid=b596c120-8114-44e8-9819-0b4dee130fa9.MOBGTAGPTB3VS24W.SEARCH&ppt=hp&ppn=homepage&ssid=s3c8i7dsvk0000001710403029549&qH=2f54b45b321e3ae5\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews.\n",
    "Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b2355c",
   "metadata": {},
   "source": [
    "1. First get the webpage \n",
    "\"https://www.flipkart.com/apple-iphone-15-black-128-gb/p/itm6ac6485515ae4?pid=MOBGTAGPTB3VS24W&lid=LSTMOBGTAGPTB3VS24WVZNSC6&marketplace=FLIPKART&q=iphone+15&store=tyy/4io&srno=s_1_2&otracker=AS_QueryStore_OrganicAutoSuggest_1_2_na_na_na&otracker1=AS_QueryStore_OrganicAutoSuggest_1_2_na_na_na&fm=organic&iid=b596c120-8114-44e8-9819-0b4dee130fa9.MOBGTAGPTB3VS24W.SEARCH&ppt=hp&ppn=homepage&ssid=s3c8i7dsvk0000001710403029549&qH=2f54b45b321e3ae5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "4d9aae45",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()              # for just opening the google chrome webdriver\n",
    "\n",
    "# for opening the flipkart website link(given) in google chrome webdriver\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-15-black-128-gb/p/itm6ac6485515ae4?pid=MOBGTAGPTB3VS24W&lid=LSTMOBGTAGPTB3VS24WVZNSC6&marketplace=FLIPKART&q=iphone+15&store=tyy/4io&srno=s_1_2&otracker=AS_QueryStore_OrganicAutoSuggest_1_2_na_na_na&otracker1=AS_QueryStore_OrganicAutoSuggest_1_2_na_na_na&fm=organic&iid=b596c120-8114-44e8-9819-0b4dee130fa9.MOBGTAGPTB3VS24W.SEARCH&ppt=hp&ppn=homepage&ssid=s3c8i7dsvk0000001710403029549&qH=2f54b45b321e3ae5\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a19fc06",
   "metadata": {},
   "source": [
    "2. First click on the \"all 1239 reviews\" to get the reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "36afc3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Click_All_Reviews= driver.find_element(By.XPATH,'//div[@class=\"_3UAT2v _16PBlm\"]/span')\n",
    "Click_All_Reviews.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e14c63",
   "metadata": {},
   "source": [
    "3. To Scrape the attributes for first 100 reviews of iphone 15: rating, Review summary, full review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "d7fcec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating=[]\n",
    "Review_Summary=[]\n",
    "Full_Review=[]\n",
    "# giving the start and end range of the pages for scraping the first 100 reviews\n",
    "start=0  # start page\n",
    "end=10    # end page\n",
    "for page in range(start,end):\n",
    "    ratings=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]') # To scrape of all 100 Rating of iphone15 from start page to end page after clicking on the next button\n",
    "    #print(len(ratings))\n",
    "    #print(ratings)\n",
    "    ReviewSummaries=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')# To scrape all 100 Review summary of iphone15 from start page to end page after clicking on the next button\n",
    "    #print(len(ReviewSummaries))\n",
    "    #print(ReviewSummaries)\n",
    "    FullReviews=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]/div[1]/div')# To scrape all 100 full review of iphone15 from start page to end page after clicking on the next button\n",
    "    #print(len(FullReviews))\n",
    "    #print(FullReviews)\n",
    "    for i in ratings:\n",
    "        Rating.append(i.text)  \n",
    "    for j in ReviewSummaries:\n",
    "        Review_Summary.append(j.text)\n",
    "    for k in FullReviews:\n",
    "        Full_Review.append(k.text)\n",
    "    # to find the element of the next button and then click on the next button\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]/span')\n",
    "    next_button.click()\n",
    "    # for giving some time delay jumping from one page to another\n",
    "    time.sleep(3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "228f0fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "#checking the length of each of the list\n",
    "print(len(Rating),len(Review_Summary),len(Full_Review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "a9e1a5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n",
      "   Rating         Review_Summary  \\\n",
      "0       5              Just wow!   \n",
      "1       4            Good choice   \n",
      "2       5  Mind-blowing purchase   \n",
      "3       4        Worth the money   \n",
      "4       5         Classy product   \n",
      "..    ...                    ...   \n",
      "95      5         Simply awesome   \n",
      "96      5          Great product   \n",
      "97      5    Best in the market!   \n",
      "98      5              Fabulous!   \n",
      "99      5              Fabulous!   \n",
      "\n",
      "                                          Full_Review  \n",
      "0                Camera Quality Is Improved Loving It  \n",
      "1                                           Very nice  \n",
      "2                                High quality camera😍  \n",
      "3   Best mobile phone\\nCamera quality is very nice...  \n",
      "4                                             Nice ❤️  \n",
      "..                                                ...  \n",
      "95  This is my first iphone ever used loving it al...  \n",
      "96  Awesome phone powerful performance and battery...  \n",
      "97  48 megapixel is lit🔥\\nThin bessels compared to...  \n",
      "98           It looks so good in my hand !.......WAU?  \n",
      "99  It's performance is super and nice camera also...  \n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe of the scraped data\n",
    "df=pd.DataFrame({'Rating':Rating,'Review_Summary':Review_Summary,'Full_Review':Full_Review}) \n",
    "print(df.shape)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff409dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
